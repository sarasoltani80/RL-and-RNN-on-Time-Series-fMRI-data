{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba9992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac93f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_center = \"NYU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1170641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2b90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 is for asd and 0 is for healthy\n",
    "df_labels = pd.read_csv('/content/drive/My Drive/Phenotypic_V1_0b_preprocessed1.csv')#path\n",
    "df_labels.DX_GROUP = df_labels.DX_GROUP.map({1: 1, 2:0})\n",
    "\n",
    "\n",
    "labels = {}\n",
    "for row in df_labels.iterrows():\n",
    "    file_id = row[1]['FILE_ID']\n",
    "    y_label = row[1]['DX_GROUP']\n",
    "    if file_id == 'no_filename':\n",
    "        continue\n",
    "    assert(file_id not in labels)\n",
    "    labels[file_id] = y_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55d3c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(filename):\n",
    "    f_split = filename.split('_')\n",
    "    if f_split[3] == 'rois':\n",
    "        key = '_'.join(f_split[0:3])\n",
    "    else:\n",
    "        key = '_'.join(f_split[0:2])\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bd9c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_main_path = '/content/drive/My Drive/cc400precdata/ABIDE_pcp/cpac/filt_global' #path to time series data\n",
    "#data_main_path = '/content/drive/My Drive/power264'\n",
    "flist = os.listdir(data_main_path)\n",
    "print(len(flist))\n",
    "\n",
    "for f in range(len(flist)):\n",
    "    flist[f] = get_key(flist[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac39c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_dict = {}\n",
    "for f in flist:\n",
    "    key = f.split('_')[0]\n",
    "\n",
    "    if key not in centers_dict:\n",
    "        centers_dict[key] = []\n",
    "    centers_dict[key].append(f)\n",
    "\n",
    "flist = np.array(centers_dict[p_center])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33834df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_labels = []\n",
    "for f in flist:\n",
    "    ASD_labels.append(labels[f])\n",
    "\n",
    "print(len(ASD_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6de40ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/content/drive/My Drive/cc400precdata/ABIDE_pcp/cpac/filt_global'\n",
    "fMRI_samples = []\n",
    "selected_files = [f for f in os.listdir(folder_path) if f.startswith('NYU')]\n",
    "print(selected_files)\n",
    "for file_name in selected_files:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    data = np.loadtxt(file_path)\n",
    "    print(data.shape)\n",
    "    fMRI_samples.append(data)\n",
    "\n",
    "fMRI_data = np.array(fMRI_samples)\n",
    "print(fMRI_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7958dd",
   "metadata": {},
   "source": [
    "### using RNN for some sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7b4166",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(fMRI_data, ASD_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e4073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2):\n",
    "        super(DeepLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b391ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 392  # Number of brain regions \n",
    "hidden_size = 128\n",
    "output_size = 2  \n",
    "num_layers = 3  \n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = DeepLSTM(input_size, hidden_size, output_size, num_layers).to('cuda')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00977a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions)\n",
    "    recall = recall_score(all_labels, all_predictions)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "\n",
    "# Evaluate the trained model\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6827006e",
   "metadata": {},
   "source": [
    "### using reinforcement learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9014919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch stable-baselines3 gym numpy matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e46ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install shimmy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba1e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "scaler = StandardScaler()\n",
    "num_samples = fMRI_data.shape[0]\n",
    "reshaped_data = fMRI_data.reshape(-1, 392)\n",
    "\n",
    "\n",
    "normalized_data = scaler.fit_transform(reshaped_data)\n",
    "\n",
    "fMRI_data_normalized = normalized_data.reshape(num_samples, 296, 392)\n",
    "\n",
    "print(fMRI_data_normalized.shape)\n",
    "\n",
    "fMRI_data_tensor = torch.tensor(fMRI_data_normalized, dtype=torch.float32)\n",
    "ASD_labels_tensor = torch.tensor(ASD_labels, dtype=torch.long)\n",
    "\n",
    "print(fMRI_data_tensor.shape)\n",
    "print(ASD_labels_tensor.shape)\n",
    "\n",
    "\n",
    "fMRI_train, fMRI_test, labels_train, labels_test = train_test_split(\n",
    "    fMRI_data_tensor, ASD_labels_tensor, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(fMRI_train.shape)\n",
    "print(labels_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67ac1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "for i in range(fMRI_data.shape[0]):\n",
    "    fMRI_data[i] = scaler.fit_transform(fMRI_data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51695188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the LSTM network for feature extraction\n",
    "class LSTMFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMFeatureExtractor, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_lstm, _ = self.lstm(x)  # LSTM output\n",
    "        h_last = h_lstm[:, -1, :]  # Get the last hidden state\n",
    "        out = self.fc(h_last)  # Fully connected layer\n",
    "        return out\n",
    "\n",
    "# Example input shape (batch_size, time_steps, num_features)\n",
    "input_size = fMRI_data.shape[2]\n",
    "hidden_size = 296  # Number of LSTM units\n",
    "output_size = 296  # Output feature size\n",
    "\n",
    "# Initialize the LSTM feature extractor\n",
    "lstm_model = LSTMFeatureExtractor(input_size, hidden_size, output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2a3ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Create a custom Gym environment\n",
    "class FMRIEnv(gym.Env):\n",
    "    def __init__(self, fMRI_data, ASD_labels, lstm_model):\n",
    "        super(FMRIEnv, self).__init__()\n",
    "        self.fMRI_data = torch.tensor(fMRI_data, dtype=torch.float32)\n",
    "        self.labels = ASD_labels\n",
    "        self.lstm_model = lstm_model\n",
    "        self.current_step = 0\n",
    "        self.num_samples = len(ASD_labels)\n",
    "\n",
    "        # Action space: classify as ASD (1) or TD (0)\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "        # Observation space: feature vector output from the LSTM\n",
    "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(296,), dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = np.random.randint(0, self.num_samples)\n",
    "        # Extract features using LSTM\n",
    "        features = self.lstm_model(self.fMRI_data[self.current_step:self.current_step+1])\n",
    "        return features.detach().numpy().squeeze()\n",
    "\n",
    "    def step(self, action):\n",
    "        label = self.labels[self.current_step]\n",
    "        reward = 1 if action == label else -1  # Reward based on correct classification\n",
    "        done = True  # Single-step environment\n",
    "        features = self.lstm_model(self.fMRI_data[self.current_step:self.current_step+1])\n",
    "        return features.detach().numpy().squeeze(), reward, done, {}\n",
    "\n",
    "# Initialize the environment\n",
    "env = DummyVecEnv([lambda: FMRIEnv(fMRI_train, labels_train, lstm_model)])\n",
    "test_env = DummyVecEnv([lambda: FMRIEnv(fMRI_test, labels_test, lstm_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd7dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DQN agent\n",
    "dqn_agent = DQN('MlpPolicy', env, verbose=1)\n",
    "\n",
    "# Train the agent\n",
    "dqn_agent.learn(total_timesteps=20000)  # Adjust the timesteps based on your data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b174dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_agent(agent, test_env, test_labels):\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    # Set the environment to the test environment\n",
    "    test_env.reset()\n",
    "\n",
    "    for i in range(len(test_labels)):\n",
    "        # Get observation from the test environment\n",
    "        obs = test_env.reset()\n",
    "        # Get the agent's action\n",
    "        action, _ = agent.predict(obs)\n",
    "        # Store the prediction and true label\n",
    "        predictions.append(action)\n",
    "        true_labels.append(test_labels[i])\n",
    "\n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions)\n",
    "    recall = recall_score(true_labels, predictions)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "\n",
    "# Evaluate the trained agent with the test data\n",
    "evaluate_agent(dqn_agent, test_env, labels_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
